{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxSLy7y3hMN_"
   },
   "source": [
    "## BMEG 457 Prototype\n",
    "\n",
    "This notebook is a prototype of a machine learning pipeline that integrates Shapely values for data valuation.\n",
    "\n",
    "The diagram below illustrates where the dataset should reside locally for loading it into this notebook. Note that the `data` directory is git ignored.\n",
    "\n",
    "```markdown\n",
    "prototype/data/\n",
    "    ├── train/\n",
    "    │     ├── NORMAL/\n",
    "    │     └── PNEUMONIA/\n",
    "    └── test/\n",
    "            ├── NORMAL/\n",
    "            └── PNEUMONIA/\n",
    "```\n",
    "\n",
    "Dataset: [chest-xray-dataset](https://www.kaggle.com/datasets/alifrahman/chestxraydataset?resource=download-directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOUxfRH4rAvc",
    "outputId": "0d64d0e4-8871-4413-9431-5b06ab4c1165"
   },
   "source": [
    "## Install dependencies and import libraries\n",
    "\n",
    "Before running this notebook, install dependencies:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNKCzQgrsRTr"
   },
   "outputs": [],
   "source": "# Standard library imports\nimport os\n\n# Data manipulation and analysis\nimport pandas as pd\nimport numpy as np\n\n# PyTorch and deep learning\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split, Subset\nfrom torchvision import datasets, transforms, models\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n# Set up data paths\ndata_root = \"data\"\ntrain_dir = os.path.join(data_root, \"train\")\ntest_dir  = os.path.join(data_root, \"test\")\n\nprint(\"Train dir:\", train_dir)\nprint(\"Test dir:\", test_dir)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS9U2A_Brg_Z"
   },
   "source": [
    "## Image transforms configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization stats\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdSVYmmlsOSv"
   },
   "source": [
    "## Load datasets and make a train/val split\n",
    "\n",
    "We’ll split the original train folder into train + val (e.g., 80/20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3skyj8gYsDSA",
    "outputId": "f959908f-b2c3-4237-faa1-af5003354515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['NORMAL', 'PNEUMONIA']  | num_classes: 2\n",
      "Train size: 4173, Val size: 1043, Test size: 624\n"
     ]
    }
   ],
   "source": [
    "# Full training dataset (from train_dir)\n",
    "full_train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "class_names = full_train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names, \" | num_classes:\", num_classes)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=eval_transform)\n",
    "\n",
    "# Train/val split\n",
    "val_fraction = 0.2\n",
    "val_size = int(len(full_train_dataset) * val_fraction)\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "print(f\"Train size: {train_size}, Val size: {val_size}, Test size: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PwIjX2WsXl4"
   },
   "source": [
    "## Define MobileNetV2 model for 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJPsWMaBsXUT",
    "outputId": "ffcf8ac2-61dc-4095-eff2-6b18ceed0b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /Users/jaidensiu/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load pretrained MobileNetV2\n",
    "base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "# Freeze feature extractor for faster training (optional)\n",
    "for param in base_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier head\n",
    "in_features = base_model.classifier[1].in_features\n",
    "base_model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2tQV41msbp5"
   },
   "source": [
    "## Training & evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EhzKHGaOsdUP"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEMCoOJhse3H"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzeoJ-d-shtG",
    "outputId": "a3b5ef28-aef2-4188-c0f8-14f89e2ba55b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Loss: 0.3137 Acc: 0.8763 | Val Loss: 0.2142 Acc: 0.9156\n",
      "Epoch 2/2 | Train Loss: 0.1951 Acc: 0.9276 | Val Loss: 0.1753 Acc: 0.9262\n",
      "Best val accuracy: 0.9261744966442953\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "num_epochs = 2  # you can increase later (e.g., 10)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state_dict = model.state_dict().copy()\n",
    "\n",
    "print(\"Best val accuracy:\", best_val_acc)\n",
    "if best_state_dict is not None:\n",
    "    model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVCw_ADuuVud",
    "outputId": "e823f94f-2c39-4170-9b78-5519f4596d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4871 | Test Acc: 0.7772\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0FOA5yKuaEg"
   },
   "source": [
    "## Build a feature extractor from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "v6KcVe8euZU2",
    "outputId": "69388e7f-1b89-4426-e809-6848d59f4847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new MobileNetV2 with same architecture and load trained weights\n",
    "feature_model = models.mobilenet_v2(weights=None)\n",
    "feature_model.classifier[1] = nn.Linear(feature_model.classifier[1].in_features, num_classes)\n",
    "feature_model.load_state_dict(model.state_dict())\n",
    "\n",
    "# Replace classifier with Identity so output is feature embedding\n",
    "feature_model.classifier = nn.Identity()\n",
    "feature_model = feature_model.to(device)\n",
    "feature_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "satQws8DuepO"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(dataloader, model, device):\n",
    "    all_feats = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            feats = model(images)  # [B, D]\n",
    "            all_feats.append(feats.cpu())\n",
    "            all_labels.append(labels)\n",
    "    return torch.cat(all_feats, dim=0), torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7GfZyH6ufNi",
    "outputId": "962e4417-c400-4bd9-c7db-e00c0ebe775d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feats: torch.Size([4173, 1280]) Val feats: torch.Size([1043, 1280])\n"
     ]
    }
   ],
   "source": [
    "train_feats, train_labels = get_embeddings(\n",
    "    DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2),\n",
    "    feature_model,\n",
    "    device\n",
    ")\n",
    "val_feats, val_labels = get_embeddings(\n",
    "    DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2),\n",
    "    feature_model,\n",
    "    device\n",
    ")\n",
    "\n",
    "print(\"Train feats:\", train_feats.shape, \"Val feats:\", val_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQL_aJDuulmS"
   },
   "source": [
    "## KNN-style data Shapley approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0Jgea5pHulIc"
   },
   "outputs": [],
   "source": [
    "# L2 normalize the embeddings for cosine similarity\n",
    "train_feats_norm = F.normalize(train_feats, p=2, dim=1)  # [N_train, D]\n",
    "val_feats_norm   = F.normalize(val_feats,   p=2, dim=1)  # [N_val, D]\n",
    "\n",
    "N_train = train_feats_norm.shape[0]\n",
    "N_val   = val_feats_norm.shape[0]\n",
    "\n",
    "data_values = torch.zeros(N_train)\n",
    "\n",
    "k = 10               # number of neighbors to consider\n",
    "val_batch_size = 64  # for similarity computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHg-NsMRuqVr",
    "outputId": "b71c3146-0bf5-49af-d623-065c76f302c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data values shape: torch.Size([4173])\n",
      "Min value: -0.7000000476837158 Max value: 3.599998712539673\n"
     ]
    }
   ],
   "source": [
    "for start in range(0, N_val, val_batch_size):\n",
    "    end = min(start + val_batch_size, N_val)\n",
    "    val_batch = val_feats_norm[start:end]          # [B, D]\n",
    "    val_labels_batch = val_labels[start:end]       # [B]\n",
    "\n",
    "    # Cosine similarity to all train samples: [B, N_train]\n",
    "    sims = val_batch @ train_feats_norm.T\n",
    "\n",
    "    # Top-k neighbors for each val sample\n",
    "    topk_sims, topk_idx = torch.topk(sims, k=k, dim=1)\n",
    "\n",
    "    for b in range(topk_idx.shape[0]):\n",
    "        v_label = val_labels_batch[b]\n",
    "        neighbors = topk_idx[b]              # indices in [0, N_train)\n",
    "        neigh_labels = train_labels[neighbors]\n",
    "\n",
    "        same = (neigh_labels == v_label).float()\n",
    "        # +1 for same-label neighbors, -1 for different-label neighbors\n",
    "        contrib = same * 1.0 - (1.0 - same) * 1.0\n",
    "\n",
    "        # Optionally weight by similarity:\n",
    "        # contrib = contrib * topk_sims[b]\n",
    "\n",
    "        # Average over k and add to data_values\n",
    "        data_values[neighbors] += contrib / k\n",
    "\n",
    "print(\"Data values shape:\", data_values.shape)\n",
    "print(\"Min value:\", data_values.min().item(), \"Max value:\", data_values.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmyMTLQzu0Gz"
   },
   "source": [
    "## Rank training samples and build a reduced training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9HY2TD4u0vh",
    "outputId": "3fe8f222-f6d0-4b43-963f-1834e28ef89e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 3755 out of 4173 training samples.\n"
     ]
    }
   ],
   "source": [
    "sorted_idx = torch.argsort(data_values, descending=True)\n",
    "\n",
    "# Example: keep top 90% most valuable training samples\n",
    "keep_fraction = 0.9\n",
    "keep_n = int(len(sorted_idx) * keep_fraction)\n",
    "\n",
    "keep_idx = sorted_idx[:keep_n]\n",
    "drop_idx = sorted_idx[keep_n:]\n",
    "\n",
    "print(\"Keeping\", keep_n, \"out of\", len(sorted_idx), \"training samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50chlkiQG6AR"
   },
   "source": [
    "This next line of code will tell us which pictures are most important and the value of importance assigned to that image by shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdBOJugoCuPz",
    "outputId": "d1e7e0a5-5c69-4336-b230-a5af6c012c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3783,  341, 1547,  968, 3837, 3581,  800, 1939, 3851,  670,  418])\n",
      "tensor([3.6000, 3.4000, 2.8000, 2.8000, 2.6000, 2.5000, 2.4000, 2.4000, 2.0000,\n",
      "        1.9000, 1.9000, 1.9000, 1.8000, 1.8000, 1.8000])\n"
     ]
    }
   ],
   "source": [
    "print(sorted_idx[:11]) # gives the index of image that are most valuable\n",
    "print(data_values[sorted_idx[:15]]) # gives the value of important images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBTGMvXgu4vp",
    "outputId": "6692a56b-e2f8-4427-af91-39d7243d27fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced train size: 3755\n"
     ]
    }
   ],
   "source": [
    "reduced_train_dataset = Subset(train_dataset, keep_idx.tolist())\n",
    "print(\"Reduced train size:\", len(reduced_train_dataset))\n",
    "\n",
    "reduced_train_loader = DataLoader(reduced_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htBkCMVXu8KQ",
    "outputId": "420b7c38-c0c3-4e52-9cf4-e6aeb17e4a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reduced] Epoch 1/2 | Train Loss: 0.2997 Acc: 0.8812 | Val Loss: 0.2183 Acc: 0.9243\n",
      "[Reduced] Epoch 2/2 | Train Loss: 0.1710 Acc: 0.9377 | Val Loss: 0.1746 Acc: 0.9358\n",
      "[Reduced] Test Loss: 0.4315 | Test Acc: 0.7917\n"
     ]
    }
   ],
   "source": [
    "def train_model_on_dataset(train_ds, val_ds, num_epochs=5):\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"[Reduced] Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict().copy()\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "reduced_model = train_model_on_dataset(reduced_train_dataset, val_dataset, num_epochs=2)\n",
    "reduced_test_loss, reduced_test_acc = evaluate(reduced_model, test_loader, criterion, device)\n",
    "print(f\"[Reduced] Test Loss: {reduced_test_loss:.4f} | Test Acc: {reduced_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53YsiplN5o_A"
   },
   "source": [
    "## Full-dataset model: tracking training & test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkSMeKg35rn5",
    "outputId": "ce0e120a-aeb4-441f-aea5-565e9a948f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4871 | Test Acc: 0.7772\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqL0lCZR5vys",
    "outputId": "2f90db4d-7b4e-4cb0-e55b-07d929d8554d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1612 | Train Acc: 0.9408\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = evaluate(model, train_loader, criterion, device)\n",
    "print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "full_train_acc = train_acc\n",
    "full_test_acc = test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Frp7T425w9S"
   },
   "source": [
    "## Reduced-dataset model: tracking training & test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBo_98Ls54cE",
    "outputId": "209b670d-1e42-4bd2-c04d-a5eb07523dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reduced] Train Acc: 0.9590\n",
      "[Reduced] Test Acc: 0.7917\n"
     ]
    }
   ],
   "source": [
    "reduced_train_loss, reduced_train_acc = evaluate(reduced_model, reduced_train_loader, criterion, device)\n",
    "reduced_test_loss, reduced_test_acc = evaluate(reduced_model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"[Reduced] Train Acc: {reduced_train_acc:.4f}\")\n",
    "print(f\"[Reduced] Test Acc: {reduced_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U90pBl1W570N"
   },
   "source": [
    "## Final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7N0Cz1q57Mw",
    "outputId": "7ddfd54a-7b03-4382-c4ff-0ce9b73bf508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARISON ===\n",
      "Full Data Model:     TrainAcc=0.9408 | TestAcc=0.7772\n",
      "Reduced Data Model:  TrainAcc=0.9590 | TestAcc=0.7917\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== COMPARISON ===\")\n",
    "print(f\"Full Data Model:     TrainAcc={full_train_acc:.4f} | TestAcc={full_test_acc:.4f}\")\n",
    "print(f\"Reduced Data Model:  TrainAcc={reduced_train_acc:.4f} | TestAcc={reduced_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4k_qwVWEI40"
   },
   "source": [
    "## Plot 2 points: Full vs Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "7Taun-cdDHGv",
    "outputId": "8576bcfd-7abe-4e26-8050-e05367024a43"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace these with your real results:\n",
    "acc_full  = 0.8093   # test accuracy using 100% of dataset\n",
    "acc_half  = 0.7869   # test accuracy using 90% of high-value images\n",
    "\n",
    "fractions = [100, 90]\n",
    "accuracies = [acc_full, acc_half]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fractions, accuracies, marker='o', linewidth=2)\n",
    "\n",
    "plt.title(\"Test Accuracy vs Dataset Size\")\n",
    "plt.xlabel(\"Dataset Size (% of training samples used)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "\n",
    "plt.xticks([90, 100])\n",
    "plt.ylim(min(accuracies) - 0.02, max(accuracies) + 0.02)\n",
    "plt.grid(True)\n",
    "\n",
    "for x, y in zip(fractions, accuracies):\n",
    "    plt.text(x, y, f\"{y:.3f}\", fontsize=10, ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cpsc340",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}