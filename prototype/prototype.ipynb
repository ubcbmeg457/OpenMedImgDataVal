{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxSLy7y3hMN_"
   },
   "source": [
    "## BMEG 457 Prototype\n",
    "\n",
    "This notebook is a prototype of a machine learning pipeline that integrates Shapely values for data valuation.\n",
    "\n",
    "The diagram below illustrates where the dataset should reside locally for loading it into this notebook. Note that the `data` directory is git ignored.\n",
    "\n",
    "```markdown\n",
    "prototype/data/\n",
    "    ├── train/\n",
    "    │     ├── NORMAL/\n",
    "    │     └── PNEUMONIA/\n",
    "    └── test/\n",
    "            ├── NORMAL/\n",
    "            └── PNEUMONIA/\n",
    "```\n",
    "\n",
    "Dataset: [chest-xray-dataset](https://www.kaggle.com/datasets/alifrahman/chestxraydataset?resource=download-directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNKCzQgrsRTr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir: data/train\n",
      "Test dir: data/test\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch and deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# Set up data paths\n",
    "data_root = \"data\"\n",
    "train_dir = os.path.join(data_root, \"train\")\n",
    "test_dir = os.path.join(data_root, \"test\")\n",
    "\n",
    "print(\"Train dir:\", train_dir)\n",
    "print(\"Test dir:\", test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS9U2A_Brg_Z"
   },
   "source": [
    "## Image transforms configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization stats\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "eval_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdSVYmmlsOSv"
   },
   "source": [
    "## Load datasets and make a train/val split\n",
    "\n",
    "We’ll split the original train folder into train + val (e.g., 80/20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3skyj8gYsDSA",
    "outputId": "f959908f-b2c3-4237-faa1-af5003354515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['NORMAL', 'PNEUMONIA']  | num_classes: 2\n",
      "Train size: 4173, Val size: 1043, Test size: 624\n"
     ]
    }
   ],
   "source": [
    "# Full training dataset (from train_dir)\n",
    "full_train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "class_names = full_train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names, \" | num_classes:\", num_classes)\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=eval_transform)\n",
    "\n",
    "# Train/val split\n",
    "val_fraction = 0.2\n",
    "val_size = int(len(full_train_dataset) * val_fraction)\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "print(f\"Train size: {train_size}, Val size: {val_size}, Test size: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PwIjX2WsXl4"
   },
   "source": [
    "## Define MobileNetV2 model for 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJPsWMaBsXUT",
    "outputId": "ffcf8ac2-61dc-4095-eff2-6b18ceed0b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load pretrained MobileNetV2\n",
    "base_model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "\n",
    "# Freeze feature extractor for faster training (optional)\n",
    "for param in base_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier head\n",
    "in_features = base_model.classifier[1].in_features\n",
    "base_model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "model = base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2tQV41msbp5"
   },
   "source": [
    "## Training & evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EhzKHGaOsdUP"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEMCoOJhse3H"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzeoJ-d-shtG",
    "outputId": "a3b5ef28-aef2-4188-c0f8-14f89e2ba55b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Loss: 0.3169 Acc: 0.8692 | Val Loss: 0.1985 Acc: 0.9386\n",
      "Epoch 2/2 | Train Loss: 0.2004 Acc: 0.9257 | Val Loss: 0.1635 Acc: 0.9406\n",
      "Best val accuracy: 0.9405560882070949\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "num_epochs = 2  # you can increase later (e.g., 10)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state_dict = model.state_dict().copy()\n",
    "\n",
    "print(\"Best val accuracy:\", best_val_acc)\n",
    "if best_state_dict is not None:\n",
    "    model.load_state_dict(best_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVCw_ADuuVud",
    "outputId": "e823f94f-2c39-4170-9b78-5519f4596d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4455 | Test Acc: 0.7933\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0FOA5yKuaEg"
   },
   "source": [
    "## Build a feature extractor from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "v6KcVe8euZU2",
    "outputId": "69388e7f-1b89-4426-e809-6848d59f4847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new MobileNetV2 with same architecture and load trained weights\n",
    "feature_model = models.mobilenet_v2(weights=None)\n",
    "feature_model.classifier[1] = nn.Linear(feature_model.classifier[1].in_features, num_classes)\n",
    "feature_model.load_state_dict(model.state_dict())\n",
    "\n",
    "# Replace classifier with Identity so output is feature embedding\n",
    "feature_model.classifier = nn.Identity()\n",
    "feature_model = feature_model.to(device)\n",
    "feature_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "satQws8DuepO"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(dataloader, model, device):\n",
    "    all_feats = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            feats = model(images)  # [B, D]\n",
    "            all_feats.append(feats.cpu())\n",
    "            all_labels.append(labels)\n",
    "    return torch.cat(all_feats, dim=0), torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7GfZyH6ufNi",
    "outputId": "962e4417-c400-4bd9-c7db-e00c0ebe775d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feats: torch.Size([4173, 1280]) Val feats: torch.Size([1043, 1280])\n"
     ]
    }
   ],
   "source": [
    "train_feats, train_labels = get_embeddings(\n",
    "    DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2), feature_model, device\n",
    ")\n",
    "val_feats, val_labels = get_embeddings(\n",
    "    DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2), feature_model, device\n",
    ")\n",
    "\n",
    "print(\"Train feats:\", train_feats.shape, \"Val feats:\", val_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQL_aJDuulmS"
   },
   "source": [
    "## KNN-style data Shapley approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0Jgea5pHulIc"
   },
   "outputs": [],
   "source": [
    "# L2 normalize the embeddings for cosine similarity\n",
    "train_feats_norm = F.normalize(train_feats, p=2, dim=1)  # [N_train, D]\n",
    "val_feats_norm = F.normalize(val_feats, p=2, dim=1)  # [N_val, D]\n",
    "\n",
    "N_train = train_feats_norm.shape[0]\n",
    "N_val = val_feats_norm.shape[0]\n",
    "\n",
    "data_values = torch.zeros(N_train)\n",
    "\n",
    "k = 10  # number of neighbors to consider\n",
    "val_batch_size = 64  # for similarity computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHg-NsMRuqVr",
    "outputId": "b71c3146-0bf5-49af-d623-065c76f302c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data values shape: torch.Size([4173])\n",
      "Min value: -1.0000001192092896 Max value: 2.8999993801116943\n"
     ]
    }
   ],
   "source": [
    "for start in range(0, N_val, val_batch_size):\n",
    "    end = min(start + val_batch_size, N_val)\n",
    "    val_batch = val_feats_norm[start:end]  # [B, D]\n",
    "    val_labels_batch = val_labels[start:end]  # [B]\n",
    "\n",
    "    # Cosine similarity to all train samples: [B, N_train]\n",
    "    sims = val_batch @ train_feats_norm.T\n",
    "\n",
    "    # Top-k neighbors for each val sample\n",
    "    topk_sims, topk_idx = torch.topk(sims, k=k, dim=1)\n",
    "\n",
    "    for b in range(topk_idx.shape[0]):\n",
    "        v_label = val_labels_batch[b]\n",
    "        neighbors = topk_idx[b]  # indices in [0, N_train)\n",
    "        neigh_labels = train_labels[neighbors]\n",
    "\n",
    "        same = (neigh_labels == v_label).float()\n",
    "        # +1 for same-label neighbors, -1 for different-label neighbors\n",
    "        contrib = same * 1.0 - (1.0 - same) * 1.0\n",
    "\n",
    "        # Optionally weight by similarity:\n",
    "        # contrib = contrib * topk_sims[b]\n",
    "\n",
    "        # Average over k and add to data_values\n",
    "        data_values[neighbors] += contrib / k\n",
    "\n",
    "print(\"Data values shape:\", data_values.shape)\n",
    "print(\"Min value:\", data_values.min().item(), \"Max value:\", data_values.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmyMTLQzu0Gz"
   },
   "source": [
    "## Rank training samples and build a reduced training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9HY2TD4u0vh",
    "outputId": "3fe8f222-f6d0-4b43-963f-1834e28ef89e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 3755 out of 4173 training samples.\n"
     ]
    }
   ],
   "source": [
    "sorted_idx = torch.argsort(data_values, descending=True)\n",
    "\n",
    "# Example: keep top 90% most valuable training samples\n",
    "keep_fraction = 0.9\n",
    "keep_n = int(len(sorted_idx) * keep_fraction)\n",
    "\n",
    "keep_idx = sorted_idx[:keep_n]\n",
    "drop_idx = sorted_idx[keep_n:]\n",
    "\n",
    "print(\"Keeping\", keep_n, \"out of\", len(sorted_idx), \"training samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50chlkiQG6AR"
   },
   "source": [
    "This next line of code will tell us which pictures are most important and the value of importance assigned to that image by shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdBOJugoCuPz",
    "outputId": "d1e7e0a5-5c69-4336-b230-a5af6c012c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3545, 2984, 3459, 3735, 1991, 3881, 2550, 1175, 1794, 1081,  979])\n",
      "tensor([2.9000, 2.5000, 2.4000, 2.4000, 2.4000, 2.4000, 2.3000, 2.1000, 2.1000,\n",
      "        2.0000, 2.0000, 1.9000, 1.9000, 1.9000, 1.9000])\n"
     ]
    }
   ],
   "source": [
    "print(sorted_idx[:11])  # gives the index of image that are most valuable\n",
    "print(data_values[sorted_idx[:15]])  # gives the value of important images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBTGMvXgu4vp",
    "outputId": "6692a56b-e2f8-4427-af91-39d7243d27fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced train size: 3755\n"
     ]
    }
   ],
   "source": [
    "reduced_train_dataset = Subset(train_dataset, keep_idx.tolist())\n",
    "print(\"Reduced train size:\", len(reduced_train_dataset))\n",
    "\n",
    "reduced_train_loader = DataLoader(reduced_train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htBkCMVXu8KQ",
    "outputId": "420b7c38-c0c3-4e52-9cf4-e6aeb17e4a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reduced] Epoch 1/2 | Train Loss: 0.2989 Acc: 0.8796 | Val Loss: 0.2120 Acc: 0.9281\n",
      "[Reduced] Epoch 2/2 | Train Loss: 0.1801 Acc: 0.9366 | Val Loss: 0.1633 Acc: 0.9367\n",
      "[Reduced] Test Loss: 0.4314 | Test Acc: 0.7917\n"
     ]
    }
   ],
   "source": [
    "def train_model_on_dataset(train_ds, val_ds, num_epochs=5):\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "    for p in model.features.parameters():\n",
    "        p.requires_grad = False\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        print(\n",
    "            f\"[Reduced] Epoch {epoch + 1}/{num_epochs} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\"\n",
    "        )\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = model.state_dict().copy()\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "reduced_model = train_model_on_dataset(reduced_train_dataset, val_dataset, num_epochs=2)\n",
    "reduced_test_loss, reduced_test_acc = evaluate(reduced_model, test_loader, criterion, device)\n",
    "print(f\"[Reduced] Test Loss: {reduced_test_loss:.4f} | Test Acc: {reduced_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53YsiplN5o_A"
   },
   "source": [
    "## Full-dataset model: tracking training & test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkSMeKg35rn5",
    "outputId": "ce0e120a-aeb4-441f-aea5-565e9a948f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4455 | Test Acc: 0.7933\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqL0lCZR5vys",
    "outputId": "2f90db4d-7b4e-4cb0-e55b-07d929d8554d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1567 | Train Acc: 0.9449\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = evaluate(model, train_loader, criterion, device)\n",
    "print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "full_train_acc = train_acc\n",
    "full_test_acc = test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Frp7T425w9S"
   },
   "source": [
    "## Reduced-dataset model: tracking training & test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBo_98Ls54cE",
    "outputId": "209b670d-1e42-4bd2-c04d-a5eb07523dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Reduced] Train Acc: 0.9617\n",
      "[Reduced] Test Acc: 0.7917\n"
     ]
    }
   ],
   "source": [
    "reduced_train_loss, reduced_train_acc = evaluate(reduced_model, reduced_train_loader, criterion, device)\n",
    "reduced_test_loss, reduced_test_acc = evaluate(reduced_model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"[Reduced] Train Acc: {reduced_train_acc:.4f}\")\n",
    "print(f\"[Reduced] Test Acc: {reduced_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U90pBl1W570N"
   },
   "source": [
    "## Final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7N0Cz1q57Mw",
    "outputId": "7ddfd54a-7b03-4382-c4ff-0ce9b73bf508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARISON ===\n",
      "Full Data Model:     TrainAcc=0.9449 | TestAcc=0.7933\n",
      "Reduced Data Model:  TrainAcc=0.9617 | TestAcc=0.7917\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== COMPARISON ===\")\n",
    "print(f\"Full Data Model:     TrainAcc={full_train_acc:.4f} | TestAcc={full_test_acc:.4f}\")\n",
    "print(f\"Reduced Data Model:  TrainAcc={reduced_train_acc:.4f} | TestAcc={reduced_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4k_qwVWEI40"
   },
   "source": [
    "## Plot 2 points: Full vs Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "7Taun-cdDHGv",
    "outputId": "8576bcfd-7abe-4e26-8050-e05367024a43"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace these with your real results:\n",
    "acc_full = 0.8093  # test accuracy using 100% of dataset\n",
    "acc_half = 0.7869  # test accuracy using 90% of high-value images\n",
    "\n",
    "fractions = [100, 90]\n",
    "accuracies = [acc_full, acc_half]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fractions, accuracies, marker=\"o\", linewidth=2)\n",
    "\n",
    "plt.title(\"Test Accuracy vs Dataset Size\")\n",
    "plt.xlabel(\"Dataset Size (% of training samples used)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "\n",
    "plt.xticks([90, 100])\n",
    "plt.ylim(min(accuracies) - 0.02, max(accuracies) + 0.02)\n",
    "plt.grid(True)\n",
    "\n",
    "for x, y in zip(fractions, accuracies):\n",
    "    plt.text(x, y, f\"{y:.3f}\", fontsize=10, ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
