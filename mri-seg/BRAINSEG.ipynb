{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2ef20c",
   "metadata": {},
   "source": [
    "## BMEG 457: Brain MRI Segmentation (BraTS)\n",
    "\n",
    "This notebook implements a brain tumor segmentation pipeline using the BraTS 2023 adult glioma dataset.\n",
    "\n",
    "The dataset should be downloaded from [Kaggle BraTS 2023](https://www.kaggle.com/datasets/shakilrana/brats-2023-adult-glioma) and placed in a local data directory.\n",
    "\n",
    "**Dataset structure:**\n",
    "\n",
    "```markdown\n",
    "data/\n",
    "    ├── ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData/\n",
    "    │     └── BraTS-GLI-*/\n",
    "    └── ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData/\n",
    "          └── BraTS-GLI-*/\n",
    "```\n",
    "\n",
    "**Modalities:** FLAIR, T1, T1c, T2 (and segmentation labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    import kagglehub\n",
    "except ModuleNotFoundError:\n",
    "    kagglehub = None\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Dataset location\n",
    "if kagglehub is not None:\n",
    "    path = kagglehub.dataset_download(\"shakilrana/brats-2023-adult-glioma\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "    dataset_path = path\n",
    "else:\n",
    "    dataset_path = \"data\"  # For local testing\n",
    "    print(\"kagglehub not installed; using local data directory:\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup: Data paths and train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471943fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# We will work with the training folder (contains segmentation masks)\n",
    "dataset_path = \"data\"\n",
    "training_path = os.path.join(dataset_path, \"ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData\")\n",
    "\n",
    "# List all case directories recursively (some may be nested)\n",
    "train_dirs = sorted(glob.glob(os.path.join(training_path, \"**\", \"BraTS-GLI-*\"), recursive=True))\n",
    "print(\"Total training cases found:\", len(train_dirs))\n",
    "\n",
    "if len(train_dirs) == 0:\n",
    "    raise ValueError(\"No training cases were found. Check your dataset path and glob pattern.\")\n",
    "\n",
    "# Split cases into training and testing (70% train, 30% test)\n",
    "train_cases, val_cases = train_test_split(train_dirs, test_size=0.3, random_state=SEED)\n",
    "print(\"Number of training cases:\", len(train_cases))\n",
    "print(\"Number of test cases:\", len(val_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data generator and dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ad997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(case_list, modality=\"flair\"):\n",
    "    \"\"\"\n",
    "    For each case in case_list:\n",
    "      - Loads the specified modality (e.g., 'flair') and its segmentation ('seg').\n",
    "      - Selects a random slice from the 3D volumes.\n",
    "      - Normalizes the image slice to [0, 1] and resizes both image and segmentation to (128, 128).\n",
    "      - Yields a tuple (image_slice, seg_slice).\n",
    "    \"\"\"\n",
    "    for case in case_list:\n",
    "        image_file = get_modality_file(case, modality=modality)\n",
    "        seg_file = get_modality_file(case, modality=\"seg\")\n",
    "\n",
    "        if image_file is None:\n",
    "            print(f\"Image file not found for case: {case}\")\n",
    "            continue\n",
    "        if seg_file is None:\n",
    "            print(f\"Segmentation file not found for case: {case}\")\n",
    "            continue\n",
    "\n",
    "        # Load volumes (assumed to be 3D arrays)\n",
    "        image_vol = load_volume(image_file)\n",
    "        seg_vol = load_volume(seg_file)\n",
    "\n",
    "        # Check if volumes are valid\n",
    "        if image_vol.shape[2] <= 0 or seg_vol.shape[2] <= 0:\n",
    "            continue\n",
    "\n",
    "        # Randomly select a slice index\n",
    "        slice_idx = random.randint(0, image_vol.shape[2] - 1)\n",
    "        image_slice = image_vol[:, :, slice_idx]\n",
    "        seg_slice = seg_vol[:, :, slice_idx]\n",
    "\n",
    "        # Normalize image slice to [0,1]\n",
    "        image_slice = image_slice.astype(np.float32)\n",
    "        if image_slice.max() > 0:\n",
    "            image_slice /= image_slice.max()\n",
    "\n",
    "        # Expand dims to have channel dimension (H, W, 1)\n",
    "        image_slice = np.expand_dims(image_slice, axis=-1)\n",
    "\n",
    "        # Resize both image and segmentation to (128, 128)\n",
    "        image_slice = tf.image.resize(image_slice, (128, 128)).numpy()\n",
    "        seg_slice = tf.image.resize(np.expand_dims(seg_slice, axis=-1), (128, 128), method=\"nearest\").numpy()\n",
    "        seg_slice = np.squeeze(seg_slice, axis=-1).astype(np.int32)\n",
    "\n",
    "        yield image_slice, seg_slice\n",
    "\n",
    "\n",
    "# Create tf.data.Dataset objects for training and testing\n",
    "BATCH_SIZE = 4  # Adjust as needed based on memory and TPU usage\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_examples(train_cases, modality=\"flair\"),\n",
    "    output_types=(tf.float32, tf.int32),\n",
    "    output_shapes=((128, 128, 1), (128, 128)),\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(buffer_size=20).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: generate_examples(val_cases, modality=\"flair\"),\n",
    "    output_types=(tf.float32, tf.int32),\n",
    "    output_shapes=((128, 128, 1), (128, 128)),\n",
    ")\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Debug: Check that the generator yields batches\n",
    "batch_count = 0\n",
    "for _ in train_dataset.take(1):\n",
    "    batch_count += 1\n",
    "print(\"Number of batches from training generator (should be > 0):\", batch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fbbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPU Setup (if using TPU)\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n",
    "    print(\"Running on TPU:\", tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError:\n",
    "    print(\"TPU not found. Using CPU/GPU strategy.\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416457db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_middle_slice(volume, ax, title=\"\"):\n",
    "    \"\"\"\n",
    "    Plots the middle slice (along the third axis) of a 3D volume on the given matplotlib axes.\n",
    "    \"\"\"\n",
    "    slice_index = volume.shape[2] // 2  # choose the middle slice\n",
    "    ax.imshow(volume[:, :, slice_index], cmap=\"gray\")\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def visualize_samples(case_list, n_samples=2, modality=\"flair\", set_name=\"\"):\n",
    "    \"\"\"\n",
    "    Randomly selects n_samples cases from case_list, loads the modality volume,\n",
    "    and visualizes the middle slice for each.\n",
    "    \"\"\"\n",
    "    samples = random.sample(case_list, n_samples)\n",
    "    fig, axes = plt.subplots(1, n_samples, figsize=(15, 5))\n",
    "\n",
    "    # If only one sample is selected, adjust axes to be iterable.\n",
    "    if n_samples == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, case in enumerate(samples):\n",
    "        mod_file = get_modality_file(case, modality=modality)\n",
    "        if mod_file is not None:\n",
    "            volume = load_volume(mod_file)\n",
    "            case_name = os.path.basename(case)\n",
    "            title = f\"{set_name}\\nCase: {case_name}\"\n",
    "            plot_middle_slice(volume, ax=axes[i], title=title)\n",
    "        else:\n",
    "            axes[i].text(\n",
    "                0.5,\n",
    "                0.5,\n",
    "                \"Modality file not found\",\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "            )\n",
    "            axes[i].set_title(f\"{set_name}\\nCase: {os.path.basename(case)}\")\n",
    "            axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Optional: Debug - Inspect one case folder\n",
    "sample_case = train_cases[0]\n",
    "print(\"Sample case folder:\", sample_case)\n",
    "print(\"Contents of sample case:\", os.listdir(sample_case))\n",
    "\n",
    "# Visualize 2 random samples from each split using the 'flair' modality\n",
    "visualize_samples(train_cases, n_samples=2, modality=\"flair\", set_name=\"Training\")\n",
    "visualize_samples(val_cases, n_samples=2, modality=\"flair\", set_name=\"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a78d1",
   "metadata": {},
   "source": [
    "## Visualization of sample slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_volume(file_path):\n",
    "    \"\"\"Loads a NIfTI file and returns its 3D data array.\"\"\"\n",
    "    volume = nib.load(file_path).get_fdata()\n",
    "    return volume\n",
    "\n",
    "\n",
    "def get_modality_file(case_dir, modality=\"flair\"):\n",
    "    \"\"\"\n",
    "    Searches recursively for a NIfTI file in the case directory that contains the modality keyword.\n",
    "    Expected modality keywords: 'flair', 't1', 't1c', 't2', or 'seg'\n",
    "    \"\"\"\n",
    "    nii_files = glob.glob(os.path.join(case_dir, \"**\", \"*.nii*\"), recursive=True)\n",
    "    for file in nii_files:\n",
    "        if modality.lower() in file.lower():\n",
    "            return file\n",
    "    return None\n",
    "\n",
    "\n",
    "# Debug: Check a sample case for segmentation file\n",
    "sample_case = train_cases[0]\n",
    "seg_file_sample = get_modality_file(sample_case, modality=\"seg\")\n",
    "print(\"Sample case folder:\", sample_case)\n",
    "print(\"Contents of sample case:\", os.listdir(sample_case))\n",
    "print(\"Segmentation file found for sample case:\", seg_file_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters):\n",
    "    x = tf.keras.layers.Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = tf.keras.layers.Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_unet(input_shape=(128, 128, 1), num_classes=4):\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "\n",
    "    # Encoder path\n",
    "    c1 = conv_block(inputs, 64)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = conv_block(p1, 128)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = conv_block(p2, 256)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = conv_block(p3, 512)\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = conv_block(p4, 1024)\n",
    "\n",
    "    # Decoder path\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding=\"same\")(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = conv_block(u6, 512)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = conv_block(u7, 256)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = conv_block(u8, 128)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1])\n",
    "    c9 = conv_block(u9, 64)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation=\"softmax\")(c9)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model with 4 segmentation classes (background + 3 tumor sub-regions)\n",
    "with strategy.scope():\n",
    "    model = build_unet(input_shape=(128, 128, 1), num_classes=4)\n",
    "\n",
    "    # Compile with sparse categorical crossentropy (integer labels)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97379046",
   "metadata": {},
   "source": [
    "## TPU Setup and distributed training strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8f6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmedimgdataval (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
